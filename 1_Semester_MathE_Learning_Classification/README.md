# Klassifikation: Methoden und Ergebnisse

## üìÑ Projekt√ºbersicht
Dieses Projekt untersucht die Klassifikation von mathematischen Antworttypen mithilfe moderner maschineller Lernmodelle. Ziel ist es, die Leistung verschiedener Klassifikatoren wie **Random Forest**, **Logistische Regression**, **XGBoost** und **LightGBM** zu vergleichen und durch Techniken wie **Feature-Auswahl**, **Datenbalancierung (SMOTE)** und **Hyperparameter-Tuning** zu optimieren.  

Der Workflow umfasst:
- Datenvorbereitung
- Erstellung und Optimierung von Klassifikationsmodellen
- Analyse der Ergebnisse und Modellvergleich

---

## üìÅ Dateistruktur
Die wichtigsten Dateien und deren Speicherorte sind wie folgt organisiert:

### **Daten**
- **Raw Data**: `data/raw/MathE dataset.csv`  
  Enth√§lt den urspr√ºnglichen Datensatz.
- **Verarbeitete Daten**: `data/processed/processed_dataset.csv`  
  Aufbereiteter Datensatz f√ºr maschinelle Lernmodelle.

### **Modelle**
- **LightGBM-Modell**: `models/LightGBM_MathE_Classification_Fr√©d√©ric Kurbel.ipynb`  
- **Logistische Regression**: `models/LogisticRegression_MathE_Classification_Fr√©d√©ric Kurbel.ipynb`  
- **Random Forest**: `models/RandomForestClassifier_MathE_Classification_Fr√©d√©ric Kurbel.ipynb`  
- **XGBoost-Modell**: `models/XGBClassifier_MathE_Classification_Fr√©d√©ric Kurbel.ipynb`  

### **Notebooks**
- **Datenvorverarbeitung**: `notebooks/PreprocessingData_MathE_Classification_Fr√©d√©ric Kurbel.ipynb`  
  Notebook zur Datenbereinigung und -vorbereitung.

### **Berichte**
- **PDF-Bericht**: `reports/1_Semester_Classification_Project.pdf`  
  Wissenschaftliche Dokumentation des Projekts.  
- **LaTeX-Dokument**: `reports/1_Semester_Documentation_Classification.tex`  
  LaTeX-Datei f√ºr die wissenschaftliche Dokumentation.  
- **Quellenverzeichnis**: `reports/bibliography.bib`  
  Alle verwendeten Quellen im BibTeX-Format.

### **Weitere Dateien**
- **README.md**: Dieses Dokument.

---

## üöÄ Projektschritte
Das Projekt gliedert sich in folgende Hauptschritte:

1. **Datenvorbereitung**
   - Laden des Datensatzes und Bereinigung fehlender Werte.
   - Identifikation und Analyse doppelter Zeilen (2.083 doppelte Eintr√§ge).
   - Transformation von Textdaten (Bag-of-Words) und numerische Kodierung der kategorialen Merkmale.

2. **Feature-Auswahl**
   - Analyse der Feature-Wichtigkeit mit Techniken wie `Feature Importance`.
   - Reduktion irrelevanter Merkmale, um Modellstabilit√§t und Effizienz zu verbessern.

3. **Modellerstellung und Optimierung**
   - **Random Forest**: Optimierung der Modellleistung durch `GridSearchCV`.
   - **Logistische Regression**: Skalierung der Features und Anwendung von SMOTE zur Datenbalancierung.
   - **XGBoost**: Randomized Search und SMOTE zur Optimierung und Balancierung der Klassenverteilung.
   - **LightGBM**: Feature-Reduktion und Hyperparameter-Tuning zur Steigerung der Genauigkeit.

4. **Ergebnisse und Modellvergleich**
   - Die besten Ergebnisse wurden mit **XGBoost** erzielt (Genauigkeit: 65.7%), gefolgt von **LightGBM** (Genauigkeit: 65.0%).
   - Techniken wie Datenbalancierung und Hyperparameter-Tuning verbesserten die Performance erheblich.

---

## ‚úçÔ∏è Autoren
Dieses Projekt wurde erstellt von:

- **Fr√©d√©ric C. Kurbel**  
  Studiengang: Computational and Data Science  
  Kontakt: [GitHub-Profil](https://github.com/Fredeys)

- **Abdul J. Safi**  
  Studiengang: Computational and Data Science  

## üìù Lizenz
Dieses Projekt steht unter der **MIT-Lizenz**.  
Details zur Lizenz finden Sie in der Datei [LICENSE](LICENSE) im Repository.

---

## üõ†Ô∏è Voraussetzungen
Um das Projekt auszuf√ºhren, sind folgende Komponenten erforderlich:

### **Software**
- **Python 3.7+**

### **Bibliotheken**
Die ben√∂tigten Python-Bibliotheken k√∂nnen mit folgendem Befehl installiert werden:
```bash
pip install pandas numpy scikit-learn xgboost lightgbm imbalanced-learn matplotlib seaborn
```

