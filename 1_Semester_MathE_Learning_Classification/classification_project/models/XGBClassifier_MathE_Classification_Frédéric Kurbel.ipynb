{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08326fd6-c9b3-4976-967d-eba2ecc5e5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten erfolgreich geladen.\n",
      "Feature-Matrix (X): (9546, 225)\n",
      "Zielvariable (y): (9546,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Den zuvor gespeicherten Datensatz laden\n",
    "df = pd.read_csv(\"processed_dataset.csv\")\n",
    "\n",
    "# Features (X) und Zielvariable (y) definieren\n",
    "# Zielvariable hier als Beispiel: 'Type of Answer'\n",
    "X = df.drop(columns=['Type of Answer'])  # Features\n",
    "y = df['Type of Answer']  # Zielvariable\n",
    "\n",
    "print(\"Daten erfolgreich geladen.\")\n",
    "print(f\"Feature-Matrix (X): {X.shape}\")\n",
    "print(f\"Zielvariable (y): {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826d7835-112d-494b-a59b-4439c05a5ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainingsdaten: (7636, 225), Testdaten: (1910, 225)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Daten in Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Trainingsdaten: {X_train.shape}, Testdaten: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d68c65-2a35-4ad9-8ac2-9f57829f6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassifikationsbericht:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67      1002\n",
      "           1       0.63      0.61      0.62       908\n",
      "\n",
      "    accuracy                           0.65      1910\n",
      "   macro avg       0.64      0.64      0.64      1910\n",
      "weighted avg       0.64      0.65      0.64      1910\n",
      "\n",
      "Genauigkeit: 0.65\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# XGBoost-Klassifizierer initialisieren\n",
    "xgb_clf = XGBClassifier(random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen auf Testdaten\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Ergebnisse bewerten\n",
    "print(\"Klassifikationsbericht:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8fb395a-b34e-4389-87ba-e2e5a9f23599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Beste Parameter: {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100}\n",
      "Klassifikationsbericht (Optimiertes Modell):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      1002\n",
      "           1       0.63      0.60      0.61       908\n",
      "\n",
      "    accuracy                           0.64      1910\n",
      "   macro avg       0.64      0.64      0.64      1910\n",
      "weighted avg       0.64      0.64      0.64      1910\n",
      "\n",
      "Genauigkeit: 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter für die Suche definieren\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# GridSearchCV einrichten\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fache Kreuzvalidierung\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Modell trainieren\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Beste Parameter ausgeben\n",
    "print(f\"Beste Parameter: {grid_search.best_params_}\")\n",
    "\n",
    "# Bestes Modell bewerten\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "print(\"Klassifikationsbericht (Optimiertes Modell):\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred_best):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5303855-3352-4280-9be4-63aa805cbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_extended = {\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.2, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "}\n",
    "\n",
    "grid_search_ext = GridSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42),\n",
    "    param_grid=param_grid_extended,\n",
    "    cv=3,  # 3-fache Kreuzvalidierung\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_ext.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Beste Parameter (erweiterte Suche): {grid_search_ext.best_params_}\")\n",
    "\n",
    "best_model_ext = grid_search_ext.best_estimator_\n",
    "y_pred_ext = best_model_ext.predict(X_test)\n",
    "print(\"Klassifikationsbericht (Erweitertes Modell):\")\n",
    "print(classification_report(y_test, y_pred_ext))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred_ext):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199a4f0b-9c51-45fc-8141-15bff24458c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Beste Parameter: {'subsample': 0.8, 'reg_lambda': 2, 'reg_alpha': 0, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_distributions = {\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Anzahl der zufälligen Kombinationen\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(f\"Beste Parameter: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ad5587-d95c-4498-bf77-d5eee1a841ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (4.66.5)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.12/site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-09 02:06:40,870] A new study created in memory with name: no-name-7cd4b00c-3a55-4155-b21b-bcc5743c5728\n",
      "[I 2024-12-09 02:06:41,250] Trial 0 finished with value: 0.6196955970843745 and parameters: {'max_depth': 9, 'learning_rate': 0.19208896249113902, 'n_estimators': 164, 'colsample_bytree': 0.513829268781407, 'subsample': 0.5983604561999367, 'gamma': 4.888841211719245, 'reg_alpha': 0.6058620041619708, 'reg_lambda': 1.034914093155283}. Best is trial 0 with value: 0.6196955970843745.\n",
      "[I 2024-12-09 02:06:41,805] Trial 1 finished with value: 0.6259821253570839 and parameters: {'max_depth': 3, 'learning_rate': 0.10265931528356925, 'n_estimators': 273, 'colsample_bytree': 0.8584053220108572, 'subsample': 0.5010387385684734, 'gamma': 3.5030851436208383, 'reg_alpha': 0.4627313006483803, 'reg_lambda': 1.891565627469794}. Best is trial 1 with value: 0.6259821253570839.\n",
      "[I 2024-12-09 02:06:42,128] Trial 2 finished with value: 0.6402562721497466 and parameters: {'max_depth': 6, 'learning_rate': 0.2114306633421213, 'n_estimators': 88, 'colsample_bytree': 0.9143967105837378, 'subsample': 0.7119617934214655, 'gamma': 1.5459813223958534, 'reg_alpha': 0.5915088400747056, 'reg_lambda': 1.4957478918495555}. Best is trial 2 with value: 0.6402562721497466.\n",
      "[I 2024-12-09 02:06:42,701] Trial 3 finished with value: 0.6274213669528482 and parameters: {'max_depth': 5, 'learning_rate': 0.019512917709016954, 'n_estimators': 193, 'colsample_bytree': 0.7569218887006445, 'subsample': 0.613202396135905, 'gamma': 0.21477187294242805, 'reg_alpha': 0.17567043080921685, 'reg_lambda': 1.1685375355717238}. Best is trial 2 with value: 0.6402562721497466.\n",
      "[I 2024-12-09 02:06:43,455] Trial 4 finished with value: 0.6504697070947609 and parameters: {'max_depth': 8, 'learning_rate': 0.0909919138429432, 'n_estimators': 268, 'colsample_bytree': 0.6978779345226676, 'subsample': 0.8794524185914989, 'gamma': 0.9186558174258735, 'reg_alpha': 0.6656415570614165, 'reg_lambda': 1.1252419322312162}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:44,054] Trial 5 finished with value: 0.6077790655861423 and parameters: {'max_depth': 3, 'learning_rate': 0.02563849792965638, 'n_estimators': 219, 'colsample_bytree': 0.6612506539348482, 'subsample': 0.9244910433347744, 'gamma': 3.6915979340169147, 'reg_alpha': 0.8022752825499085, 'reg_lambda': 1.34827797772115}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:44,509] Trial 6 finished with value: 0.6439229763703455 and parameters: {'max_depth': 6, 'learning_rate': 0.1329188100743708, 'n_estimators': 114, 'colsample_bytree': 0.7280004047844956, 'subsample': 0.6341302587009192, 'gamma': 1.2553929860815631, 'reg_alpha': 0.38779801170994643, 'reg_lambda': 1.2372008252136817}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:45,075] Trial 7 finished with value: 0.6364582834972073 and parameters: {'max_depth': 9, 'learning_rate': 0.26370075992260605, 'n_estimators': 117, 'colsample_bytree': 0.8310870061330408, 'subsample': 0.7103845340805213, 'gamma': 0.3115694679000769, 'reg_alpha': 0.16638491389928, 'reg_lambda': 1.6552378148248588}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:45,349] Trial 8 finished with value: 0.6182549150638083 and parameters: {'max_depth': 4, 'learning_rate': 0.13228345456201862, 'n_estimators': 80, 'colsample_bytree': 0.9697274001771987, 'subsample': 0.8054798037155242, 'gamma': 3.752924048164448, 'reg_alpha': 0.4885522593777415, 'reg_lambda': 1.364660557978997}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:45,837] Trial 9 finished with value: 0.6365883847230603 and parameters: {'max_depth': 4, 'learning_rate': 0.23539889218206647, 'n_estimators': 246, 'colsample_bytree': 0.5366345468446705, 'subsample': 0.6374889722020965, 'gamma': 2.9801906288182733, 'reg_alpha': 0.19608917643138968, 'reg_lambda': 1.2762779241665578}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:46,450] Trial 10 finished with value: 0.6348868314821302 and parameters: {'max_depth': 8, 'learning_rate': 0.06961828079869037, 'n_estimators': 299, 'colsample_bytree': 0.6239823127836517, 'subsample': 0.9978802088568195, 'gamma': 1.7194272271642768, 'reg_alpha': 0.9907551286279801, 'reg_lambda': 1.7464658550658352}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:46,903] Trial 11 finished with value: 0.6424808539249774 and parameters: {'max_depth': 7, 'learning_rate': 0.15051797001529835, 'n_estimators': 149, 'colsample_bytree': 0.7117816532129824, 'subsample': 0.8263367403888366, 'gamma': 1.4748937323589202, 'reg_alpha': 0.4189343380696162, 'reg_lambda': 1.0379034094863941}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:47,412] Trial 12 finished with value: 0.6430051685528514 and parameters: {'max_depth': 7, 'learning_rate': 0.08024166789259578, 'n_estimators': 130, 'colsample_bytree': 0.7477022386272301, 'subsample': 0.8871807637927486, 'gamma': 1.0661130724068906, 'reg_alpha': 0.7560089851610594, 'reg_lambda': 1.191969823341189}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:47,875] Trial 13 finished with value: 0.6373742393399562 and parameters: {'max_depth': 6, 'learning_rate': 0.11707856235778838, 'n_estimators': 191, 'colsample_bytree': 0.6096685844141219, 'subsample': 0.790129372204536, 'gamma': 2.2908418079066806, 'reg_alpha': 0.33995719956201165, 'reg_lambda': 1.4557870054358555}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:48,191] Trial 14 finished with value: 0.6435290716307821 and parameters: {'max_depth': 7, 'learning_rate': 0.18716117682620223, 'n_estimators': 56, 'colsample_bytree': 0.6922740739823336, 'subsample': 0.8834133321498476, 'gamma': 0.6648593094131574, 'reg_alpha': 0.729453795593803, 'reg_lambda': 1.1573011280036458}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:48,855] Trial 15 finished with value: 0.6411717135550662 and parameters: {'max_depth': 8, 'learning_rate': 0.05560750138263512, 'n_estimators': 229, 'colsample_bytree': 0.8006021124885474, 'subsample': 0.5218293380773784, 'gamma': 2.1381231773371208, 'reg_alpha': 0.31543454725842746, 'reg_lambda': 1.004100990178661}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:49,225] Trial 16 finished with value: 0.638815178579237 and parameters: {'max_depth': 5, 'learning_rate': 0.2983636605327292, 'n_estimators': 104, 'colsample_bytree': 0.586182074127305, 'subsample': 0.6778167630768097, 'gamma': 0.93982886114863, 'reg_alpha': 0.006248265960088872, 'reg_lambda': 1.2650791704490705}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:50,346] Trial 17 finished with value: 0.6435305634993269 and parameters: {'max_depth': 8, 'learning_rate': 0.15816202252747058, 'n_estimators': 300, 'colsample_bytree': 0.7844399348322113, 'subsample': 0.9820950395457835, 'gamma': 0.04175823155032554, 'reg_alpha': 0.9097370501120545, 'reg_lambda': 1.6502677003932398}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:50,779] Trial 18 finished with value: 0.6335760963561884 and parameters: {'max_depth': 5, 'learning_rate': 0.09599635063674439, 'n_estimators': 144, 'colsample_bytree': 0.7010133967736369, 'subsample': 0.5689039016227921, 'gamma': 2.805785700509564, 'reg_alpha': 0.5997379348743294, 'reg_lambda': 1.3901048585994986}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:51,624] Trial 19 finished with value: 0.6486370237531194 and parameters: {'max_depth': 7, 'learning_rate': 0.04757317135090826, 'n_estimators': 262, 'colsample_bytree': 0.8654673281830836, 'subsample': 0.7579624759575638, 'gamma': 1.178311682617554, 'reg_alpha': 0.6656163086278842, 'reg_lambda': 1.1149572075054734}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:52,375] Trial 20 finished with value: 0.6423508041428675 and parameters: {'max_depth': 8, 'learning_rate': 0.04986136985388768, 'n_estimators': 267, 'colsample_bytree': 0.892113206946892, 'subsample': 0.7652263293317814, 'gamma': 1.9290203541569273, 'reg_alpha': 0.6652840332193735, 'reg_lambda': 1.1150606172181674}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:53,095] Trial 21 finished with value: 0.6444459534609036 and parameters: {'max_depth': 7, 'learning_rate': 0.13688184072630596, 'n_estimators': 260, 'colsample_bytree': 0.9937450881752534, 'subsample': 0.8468056950746956, 'gamma': 0.9781233338565232, 'reg_alpha': 0.8730385454691488, 'reg_lambda': 1.2615571148215816}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:54,102] Trial 22 finished with value: 0.6482435820072423 and parameters: {'max_depth': 7, 'learning_rate': 0.04468980216622326, 'n_estimators': 263, 'colsample_bytree': 0.9883374330265774, 'subsample': 0.8486662071125413, 'gamma': 0.5094972520244885, 'reg_alpha': 0.8467161642809953, 'reg_lambda': 1.077505055253931}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:54,964] Trial 23 finished with value: 0.6465419773225692 and parameters: {'max_depth': 9, 'learning_rate': 0.03704939722714287, 'n_estimators': 220, 'colsample_bytree': 0.9289050845552617, 'subsample': 0.9349924688659418, 'gamma': 0.623648898804529, 'reg_alpha': 0.8327374880227655, 'reg_lambda': 1.0683000496197672}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:55,931] Trial 24 finished with value: 0.6486364578719472 and parameters: {'max_depth': 7, 'learning_rate': 0.07717266335966218, 'n_estimators': 281, 'colsample_bytree': 0.9469461007994143, 'subsample': 0.8644679231858544, 'gamma': 0.5656572553765675, 'reg_alpha': 0.7012278234865388, 'reg_lambda': 1.1186563632962838}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:56,979] Trial 25 finished with value: 0.6444460563483895 and parameters: {'max_depth': 8, 'learning_rate': 0.07933617992294077, 'n_estimators': 282, 'colsample_bytree': 0.8679632332443501, 'subsample': 0.7528089552507126, 'gamma': 0.7719174034209164, 'reg_alpha': 0.6845778791289663, 'reg_lambda': 1.1187724412819777}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:57,953] Trial 26 finished with value: 0.6375056266593823 and parameters: {'max_depth': 7, 'learning_rate': 0.01639999304973857, 'n_estimators': 247, 'colsample_bytree': 0.9455971472751358, 'subsample': 0.8905760224954604, 'gamma': 1.358097237910695, 'reg_alpha': 0.5385595493994043, 'reg_lambda': 1.9998251519493198}. Best is trial 4 with value: 0.6504697070947609.\n",
      "[I 2024-12-09 02:06:58,745] Trial 27 finished with value: 0.6520416735472673 and parameters: {'max_depth': 6, 'learning_rate': 0.09830896583254517, 'n_estimators': 240, 'colsample_bytree': 0.8434904244077905, 'subsample': 0.945635148844509, 'gamma': 0.06974819787887643, 'reg_alpha': 0.6795773444621178, 'reg_lambda': 1.3192277812562867}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:06:59,467] Trial 28 finished with value: 0.650338988543993 and parameters: {'max_depth': 6, 'learning_rate': 0.09994099740363047, 'n_estimators': 201, 'colsample_bytree': 0.8251745725137298, 'subsample': 0.9532709570355863, 'gamma': 0.03896282182691968, 'reg_alpha': 0.5308941908382008, 'reg_lambda': 1.33481194182023}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:06:59,900] Trial 29 finished with value: 0.6081718385633614 and parameters: {'max_depth': 5, 'learning_rate': 0.10612841596369507, 'n_estimators': 173, 'colsample_bytree': 0.8147992030389574, 'subsample': 0.9538463590226526, 'gamma': 4.791533594472809, 'reg_alpha': 0.551082738745293, 'reg_lambda': 1.4304479220367963}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:00,626] Trial 30 finished with value: 0.6483752265453829 and parameters: {'max_depth': 6, 'learning_rate': 0.1791063512364135, 'n_estimators': 211, 'colsample_bytree': 0.7561089580815201, 'subsample': 0.9151740132505461, 'gamma': 0.08527803226706643, 'reg_alpha': 0.5962009914559866, 'reg_lambda': 1.5561984295076918}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:01,452] Trial 31 finished with value: 0.649291645381818 and parameters: {'max_depth': 6, 'learning_rate': 0.08895401067864378, 'n_estimators': 240, 'colsample_bytree': 0.8415265846522244, 'subsample': 0.9704621115421723, 'gamma': 0.017130895467357295, 'reg_alpha': 0.6338713288363079, 'reg_lambda': 1.29644556976191}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:02,247] Trial 32 finished with value: 0.6496845726902659 and parameters: {'max_depth': 6, 'learning_rate': 0.10049205925010539, 'n_estimators': 240, 'colsample_bytree': 0.7861834728455432, 'subsample': 0.9636623413005464, 'gamma': 0.048727870989879185, 'reg_alpha': 0.524606018584479, 'reg_lambda': 1.348118480112525}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:02,801] Trial 33 finished with value: 0.6443149776914209 and parameters: {'max_depth': 5, 'learning_rate': 0.11622157024504717, 'n_estimators': 193, 'colsample_bytree': 0.7862176944944699, 'subsample': 0.9549817115785337, 'gamma': 0.46682363114561665, 'reg_alpha': 0.5054426197966634, 'reg_lambda': 1.5457212503215252}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:03,476] Trial 34 finished with value: 0.648636612203176 and parameters: {'max_depth': 6, 'learning_rate': 0.16736587416110216, 'n_estimators': 200, 'colsample_bytree': 0.8932700027260132, 'subsample': 0.9128031966480492, 'gamma': 0.38618453279316534, 'reg_alpha': 0.4543813004165755, 'reg_lambda': 1.3353762896703063}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:04,225] Trial 35 finished with value: 0.6461484841329491 and parameters: {'max_depth': 6, 'learning_rate': 0.06364516491147973, 'n_estimators': 235, 'colsample_bytree': 0.6760161806098949, 'subsample': 0.943909810931722, 'gamma': 0.15423011168730308, 'reg_alpha': 0.5474828811193782, 'reg_lambda': 1.421785178805907}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:04,734] Trial 36 finished with value: 0.6335770737873038 and parameters: {'max_depth': 4, 'learning_rate': 0.1160985425924117, 'n_estimators': 212, 'colsample_bytree': 0.7793080925439366, 'subsample': 0.9969173828364648, 'gamma': 0.8470826030624878, 'reg_alpha': 0.37727742088661953, 'reg_lambda': 1.210948919973099}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:05,440] Trial 37 finished with value: 0.6471960845138386 and parameters: {'max_depth': 5, 'learning_rate': 0.09433364558594162, 'n_estimators': 254, 'colsample_bytree': 0.6539749819860456, 'subsample': 0.9109101262227449, 'gamma': 0.3169047344546899, 'reg_alpha': 0.7738940747143156, 'reg_lambda': 1.5013964807991553}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:06,018] Trial 38 finished with value: 0.6500772942237422 and parameters: {'max_depth': 6, 'learning_rate': 0.13708004169576712, 'n_estimators': 177, 'colsample_bytree': 0.7321796724174765, 'subsample': 0.9539542732844625, 'gamma': 0.288333931830451, 'reg_alpha': 0.27676838901625656, 'reg_lambda': 1.3140329886811533}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:06,442] Trial 39 finished with value: 0.6172074690141475 and parameters: {'max_depth': 6, 'learning_rate': 0.20838927054198675, 'n_estimators': 179, 'colsample_bytree': 0.7194647012726256, 'subsample': 0.9323401964227219, 'gamma': 4.483562277945426, 'reg_alpha': 0.2957922295817886, 'reg_lambda': 1.323237543309028}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:06,898] Trial 40 finished with value: 0.6465411027789395 and parameters: {'max_depth': 9, 'learning_rate': 0.13866875941886264, 'n_estimators': 160, 'colsample_bytree': 0.7345965856623599, 'subsample': 0.8689602890973631, 'gamma': 1.6899401471902675, 'reg_alpha': 0.15580574659629404, 'reg_lambda': 1.2201599300024824}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:07,630] Trial 41 finished with value: 0.6478510148049949 and parameters: {'max_depth': 6, 'learning_rate': 0.10816870076792924, 'n_estimators': 227, 'colsample_bytree': 0.8301015198513649, 'subsample': 0.9690742915098985, 'gamma': 0.2773037559846248, 'reg_alpha': 0.2665371108029382, 'reg_lambda': 1.3804701560489914}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:08,223] Trial 42 finished with value: 0.6461486384641779 and parameters: {'max_depth': 5, 'learning_rate': 0.12558786561141255, 'n_estimators': 208, 'colsample_bytree': 0.8093098595077419, 'subsample': 0.9771295871455588, 'gamma': 0.312143609661901, 'reg_alpha': 0.44696034065769397, 'reg_lambda': 1.3077231332894086}. Best is trial 27 with value: 0.6520416735472673.\n",
      "[I 2024-12-09 02:07:09,073] Trial 43 finished with value: 0.6521726493167499 and parameters: {'max_depth': 6, 'learning_rate': 0.14751782232750854, 'n_estimators': 275, 'colsample_bytree': 0.7766488973382092, 'subsample': 0.9516562498035502, 'gamma': 0.03367330199720531, 'reg_alpha': 0.5167403897206998, 'reg_lambda': 1.4729346808859045}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:09,884] Trial 44 finished with value: 0.647720141922998 and parameters: {'max_depth': 6, 'learning_rate': 0.15682527791000817, 'n_estimators': 283, 'colsample_bytree': 0.7628618837876644, 'subsample': 0.9049309651981906, 'gamma': 0.6224419844751304, 'reg_alpha': 0.09703624811203804, 'reg_lambda': 1.4882733045566559}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:10,449] Trial 45 finished with value: 0.6481118345816158 and parameters: {'max_depth': 5, 'learning_rate': 0.13911912636711413, 'n_estimators': 181, 'colsample_bytree': 0.655934261974734, 'subsample': 0.8172390772048391, 'gamma': 0.8155032235543391, 'reg_alpha': 0.4843562274497063, 'reg_lambda': 1.6188685873351796}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:11,048] Trial 46 finished with value: 0.6394696973204498 and parameters: {'max_depth': 4, 'learning_rate': 0.1693650740335698, 'n_estimators': 276, 'colsample_bytree': 0.8548137783112395, 'subsample': 0.9376992771669542, 'gamma': 1.196177324486242, 'reg_alpha': 0.6317178388096019, 'reg_lambda': 1.7155313172789923}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:11,776] Trial 47 finished with value: 0.6422199312608706 and parameters: {'max_depth': 6, 'learning_rate': 0.1244557528307181, 'n_estimators': 292, 'colsample_bytree': 0.7354684598984182, 'subsample': 0.9957729629869322, 'gamma': 0.3267004462300031, 'reg_alpha': 0.39145418398171344, 'reg_lambda': 1.4171618182535333}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:12,389] Trial 48 finished with value: 0.6326598318509818 and parameters: {'max_depth': 7, 'learning_rate': 0.1483926597163891, 'n_estimators': 252, 'colsample_bytree': 0.6872481840122754, 'subsample': 0.7100245233331661, 'gamma': 3.108677772640892, 'reg_alpha': 0.25779744513860714, 'reg_lambda': 1.172027964890087}. Best is trial 43 with value: 0.6521726493167499.\n",
      "[I 2024-12-09 02:07:12,987] Trial 49 finished with value: 0.6461482783579775 and parameters: {'max_depth': 6, 'learning_rate': 0.20460867789235115, 'n_estimators': 161, 'colsample_bytree': 0.5548608703966409, 'subsample': 0.8954953618258934, 'gamma': 0.19764582747904175, 'reg_alpha': 0.5659341092554727, 'reg_lambda': 1.5471268154082907}. Best is trial 43 with value: 0.6521726493167499.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'max_depth': 6, 'learning_rate': 0.14751782232750854, 'n_estimators': 275, 'colsample_bytree': 0.7766488973382092, 'subsample': 0.9516562498035502, 'gamma': 0.03367330199720531, 'reg_alpha': 0.5167403897206998, 'reg_lambda': 1.4729346808859045}\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1, 2),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(f\"Beste Parameter: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b241a766-fc70-4b51-b4e4-b021c5f77031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV-Modell:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66      1002\n",
      "           1       0.62      0.61      0.62       908\n",
      "\n",
      "    accuracy                           0.64      1910\n",
      "   macro avg       0.64      0.64      0.64      1910\n",
      "weighted avg       0.64      0.64      0.64      1910\n",
      "\n",
      "Genauigkeit: 0.64\n",
      "\n",
      "Optuna-Modell:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67      1002\n",
      "           1       0.63      0.64      0.63       908\n",
      "\n",
      "    accuracy                           0.65      1910\n",
      "   macro avg       0.65      0.65      0.65      1910\n",
      "weighted avg       0.65      0.65      0.65      1910\n",
      "\n",
      "Genauigkeit: 0.65\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Konfiguration aus RandomizedSearchCV\n",
    "model_random_search = XGBClassifier(\n",
    "    subsample=0.8,\n",
    "    reg_lambda=2,\n",
    "    reg_alpha=0,\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.2,\n",
    "    gamma=1,\n",
    "    colsample_bytree=0.7,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Konfiguration aus Optuna\n",
    "model_optuna = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.14751782232750854,\n",
    "    n_estimators=275,\n",
    "    colsample_bytree=0.7766488973382092,\n",
    "    subsample=0.9516562498035502,\n",
    "    gamma=0.03367330199720531,\n",
    "    reg_alpha=0.5167403897206998,\n",
    "    reg_lambda=1.4729346808859045,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Training und Bewertung des RandomizedSearchCV-Modells\n",
    "model_random_search.fit(X_train, y_train)\n",
    "y_pred_random_search = model_random_search.predict(X_test)\n",
    "print(\"RandomizedSearchCV-Modell:\")\n",
    "print(classification_report(y_test, y_pred_random_search))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred_random_search):.2f}\")\n",
    "\n",
    "# Training und Bewertung des Optuna-Modells\n",
    "model_optuna.fit(X_train, y_train)\n",
    "y_pred_optuna = model_optuna.predict(X_test)\n",
    "print(\"\\nOptuna-Modell:\")\n",
    "print(classification_report(y_test, y_pred_optuna))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred_optuna):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad6308b5-045c-4ad2-ab36-c76cb7c65aab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Importances:\n",
      "Student ID: 0.010249266400933266\n",
      "Student Country: 0.010869559831917286\n",
      "Question ID: 0.005923223681747913\n",
      "Question Level: 0.010677258484065533\n",
      "Topic: 0.01424817182123661\n",
      " and inequalities: 0.015386383980512619\n",
      " and total probability rules: 0.0032536815851926804\n",
      " equations: 0.006425110157579184\n",
      " image and graphics: 0.003429036121815443\n",
      " integration by parts: 0.0\n",
      " multiplication: 0.004050378687679768\n",
      "addition: 0.0025374596007168293\n",
      "adjacency matrix: 0.0037392766680568457\n",
      "algebraic expressions: 0.0\n",
      "algebraic form: 0.004006892908364534\n",
      "analytic geometry: 0.00290168565697968\n",
      "area : 0.0010339259169995785\n",
      "area of a planar region : 0.0\n",
      "assignment problem: 0.0\n",
      "axioms of probability: 0.003928063903003931\n",
      "basis: 0.007506234105676413\n",
      "bayes' theorem: 0.0\n",
      "bernoulli equation: 0.0\n",
      "cartesian coordinates: 0.0036970977671444416\n",
      "cartesian equations of a line: 0.0038038957864046097\n",
      "cartesian equations of a plane: 0.008650450967252254\n",
      "cauchy problem: 0.0\n",
      "chain rule: 0.0\n",
      "change-of-basis matrix: 0.005942520219832659\n",
      "changing order of integration: 0.0\n",
      "characteristic polynomial: 0.004332447424530983\n",
      "chi square distribution: 0.0010742582380771637\n",
      "chromatic number: 0.0016122466186061502\n",
      "classification of geometric solids: 0.005608853884041309\n",
      "classification of geometrical figures: 0.0007610292523168027\n",
      "collinearity: 0.008284230716526508\n",
      "commuting matrices: 0.002557481871917844\n",
      "complement of a set: 0.0\n",
      "complex numbers: 0.03326188400387764\n",
      "complex plane : 0.0032069645822048187\n",
      "composition of linear applications: 0.005410640966147184\n",
      "conditional probability: 0.0\n",
      "confidence interval: 0.0044044856913387775\n",
      "conjugate number: 0.003347823629155755\n",
      "consistent system: 0.020071661099791527\n",
      "continuity: 0.0038273148238658905\n",
      "cross product: 0.005114785861223936\n",
      "cycle and circuit: 0.0\n",
      "data type: 0.0022457828745245934\n",
      "de moivre formulas: 0.006577436346560717\n",
      "definite integrals: 0.0\n",
      "derivatives: 0.00815073773264885\n",
      "determinant computation: 0.005084345117211342\n",
      "determinant properties: 0.004969801753759384\n",
      "diagonalization: 0.010903848335146904\n",
      "differential equations: 0.004705143626779318\n",
      "dimension: 0.005799241829663515\n",
      "direct inspection: 0.005468455608934164\n",
      "direct integrals : 0.0\n",
      "directional derivative: 0.004620220512151718\n",
      "distance: 0.00478016072884202\n",
      "domain: 0.003370935097336769\n",
      "double integration: 0.0\n",
      "duality theory: 0.0018417194951325655\n",
      "eigenvalue: 0.0\n",
      "eigenvalues and eigenvectors: 0.006421297322958708\n",
      "eigenvector: 0.0037486476358026266\n",
      "elementary geometry: 0.010316506959497929\n",
      "equations involving complex numbers: 0.0\n",
      "euclidean spaces: 0.004485701210796833\n",
      "event: 0.00714509142562747\n",
      "exact differential form: 0.0\n",
      "excel solver add-in: 0.0034267320297658443\n",
      "exponential function: 0.006447535939514637\n",
      "exponential rule: 0.006560902576893568\n",
      "first order: 0.003832625225186348\n",
      "frequency: 0.002413119887933135\n",
      "fundamental theorem of calculus: 0.0005369212012737989\n",
      "geometric solids: 0.0010365970665588975\n",
      "geometric transformations: 0.007825872860848904\n",
      "geometrical figures: 0.011568577960133553\n",
      "gradient: 0.004157309886068106\n",
      "graph theory: 0.004455787595361471\n",
      "graphical method: 0.0\n",
      "hermitian matrix: 0.004605494439601898\n",
      "homogeneous equation: 0.0018648558761924505\n",
      "homogeneous system: 0.0\n",
      "hypothesis testing: 0.008815047331154346\n",
      "image of a function: 0.0037683763075619936\n",
      "imaginary part: 0.008314522914588451\n",
      "incidence matrix : 0.0\n",
      "inconsistent system: 0.003407909767702222\n",
      "independence: 0.002596975304186344\n",
      "indeterminate forms: 0.005347149446606636\n",
      "injective linear application: 0.005235819146037102\n",
      "integral curve: 0.0\n",
      "integration by parts: 0.0010356386192142963\n",
      "integration techniques: 0.007178384345024824\n",
      "interquartile range: 0.002621077001094818\n",
      "intersection: 0.0022505561355501413\n",
      "inverse matrix : 0.005274082999676466\n",
      "invertible linear operator: 0.005197011400014162\n",
      "isomorphism: 0.005156593397259712\n",
      "iterate integrals: 0.00312442728318274\n",
      "kernel: 0.005304656457155943\n",
      "lagrange multipliers: 0.002892720513045788\n",
      "lagrange's interpolation: 0.0019154472975060344\n",
      "limits: 0.007447415962815285\n",
      "limits and continuity: 0.0038553110789507627\n",
      "linear application: 0.0077273244969546795\n",
      "linear combination: 0.004807736724615097\n",
      "linear dependence: 0.007556975353509188\n",
      "linear differential equation: 0.004644736647605896\n",
      "linear equations: 0.0\n",
      "linear independence: 0.009431859478354454\n",
      "linear optimization: 0.020406607538461685\n",
      "linear programming: 0.005666513927280903\n",
      "linear regression: 0.007937275804579258\n",
      "linear systems: 0.012042218819260597\n",
      "linear transformations: 0.01065782830119133\n",
      "linearity: 0.008203374221920967\n",
      "linearly independent rows: 0.003781620878726244\n",
      "locus: 0.003452603006735444\n",
      "logarithmic function: 0.002390410518273711\n",
      "logarithmic rule: 0.0047583566047251225\n",
      "matrices and determinants: 0.007964884862303734\n",
      "matrix equivalent - echelon: 0.0049499706365168095\n",
      "matrix multiplication: 0.0036406582221388817\n",
      "matrix of a linear transformation: 0.005005329847335815\n",
      "matrix operations: 0.004661252722144127\n",
      "matrix rank: 0.007481406908482313\n",
      "maximum: 0.004008490592241287\n",
      "mean: 0.0028417680878192186\n",
      "median: 0.0063529540784657\n",
      "minimum: 0.004790152423083782\n",
      "mode: 0.0\n",
      "modulus of a complex number: 0.004971090238541365\n",
      "newtons interpolation: 0.0012609520927071571\n",
      "newtons method: 0.006129327695816755\n",
      "nonlinear equation: 0.007631705608218908\n",
      "nonlinear optimization: 0.0034652173053473234\n",
      "nth root: 0.0036697392351925373\n",
      "numerical methods: 0.004760194569826126\n",
      "operations with complex numbers: 0.008528221398591995\n",
      "optimal solution: 0.0017530411714687943\n",
      "orthogonal basis: 0.0043865409679710865\n",
      "orthogonal projection: 0.0059015825390815735\n",
      "orthogonality: 0.005065318662673235\n",
      "outliers: 0.002229736652225256\n",
      "partial differentiation: 0.012282097712159157\n",
      "partial fractions decomposition: 0.0\n",
      "path: 0.0015480904839932919\n",
      "planar graph: 0.002578124636784196\n",
      "platonic solids: 0.00318441865965724\n",
      "point estimate: 0.0068910433910787106\n",
      "polar representation: 0.007728583179414272\n",
      "polygons: 0.005453485529869795\n",
      "polyhedrons: 0.0\n",
      "polynomial interpolation: 0.003983144648373127\n",
      "population: 0.004551254212856293\n",
      "postoptimality analysis: 0.0\n",
      "power of trigonometric functions: 0.0\n",
      "power rule: 0.0031354776583611965\n",
      "principal argument: 0.0047060600481927395\n",
      "probability : 0.0027961081359535456\n",
      "product rule: 0.0046042995527386665\n",
      "quadratic equations: 0.0\n",
      "quadrilaterals: 0.002131053712219\n",
      "quantile: 0.0011942663695663214\n",
      "quotient rule: 0.003603809280321002\n",
      "range: 0.005123623181134462\n",
      "rational functions: 0.0\n",
      "real part: 0.006648414768278599\n",
      "regular polygon: 0.0012481905287131667\n",
      "relative frequency: 0.004642423242330551\n",
      "rhombus: 0.0\n",
      "rotation: 0.0\n",
      "saddle point: 0.0010774408001452684\n",
      "sample: 0.0038727668579667807\n",
      "sample space: 0.011370919644832611\n",
      "scalar product: 0.002802622504532337\n",
      "second derivative test: 0.004964563529938459\n",
      "second order: 0.004041347652673721\n",
      "sensitivity analysis: 0.0\n",
      "separable variables equation: 0.0029962006956338882\n",
      "set theory: 0.0027036690153181553\n",
      "shortest path: 0.00246543250977993\n",
      "simple graph: 0.002079622121527791\n",
      "simple integration: 0.00975059438496828\n",
      "simplex method: 0.002135751536116004\n",
      "simplify expressions: 0.008995676413178444\n",
      "solution of linear system: 0.0\n",
      "solve matrix equation: 0.0018806345760822296\n",
      "span: 0.006983979605138302\n",
      "spanning tree: 0.0\n",
      "spectrum: 0.0032471204176545143\n",
      "square linear system: 0.005691343918442726\n",
      "square roots: 0.006942468695342541\n",
      "standard deviation: 0.0012718968791887164\n",
      "stationary point: 0.004239573609083891\n",
      "statistics: 0.011316183023154736\n",
      "stem and leaf diagram: 0.0020913651678711176\n",
      "student distribution: 0.0066549270413815975\n",
      "subset: 0.003932821564376354\n",
      "subspace: 0.009139933623373508\n",
      "substitution: 0.005554556380957365\n",
      "sum rule: 0.006299952976405621\n",
      "symmetric matrix: 0.002820405876263976\n",
      "symmetry: 0.004045616369694471\n",
      "transportation problem: 0.0\n",
      "tree: 0.0\n",
      "triangle inequality: 0.002468619728460908\n",
      "triangles: 0.00581844337284565\n",
      "trigonometric form: 0.008300727233290672\n",
      "trigonometric rules: 0.017973462119698524\n",
      "trigonometric substitution: 0.0025194366462528706\n",
      "unconstrained optimization: 0.0017809104174375534\n",
      "undetermined solution of linear system: 0.0\n",
      "union of sets: 0.0\n",
      "variance: 0.008044489659368992\n",
      "vector spaces: 0.009248296730220318\n",
      "venn diagram: 0.0\n",
      "volume of revolution: 0.0\n",
      "x-simple region (type ii): 0.0\n",
      "y-simple region (type i): 0.004285155329853296\n",
      "Reduzierte Feature-Matrix nach Selektion: (7636, 99)\n",
      "Trainingsdaten nach SMOTE: (8148, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassifikationsbericht (Finales Modell):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64      1002\n",
      "           1       0.61      0.65      0.63       908\n",
      "\n",
      "    accuracy                           0.64      1910\n",
      "   macro avg       0.64      0.64      0.64      1910\n",
      "weighted avg       0.64      0.64      0.64      1910\n",
      "\n",
      "Genauigkeit: 0.64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Initiales Modell für Feature-Importance\n",
    "initial_model = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.14751782232750854,\n",
    "    n_estimators=275,\n",
    "    colsample_bytree=0.7766488973382092,\n",
    "    subsample=0.9516562498035502,\n",
    "    gamma=0.03367330199720531,\n",
    "    reg_alpha=0.5167403897206998,\n",
    "    reg_lambda=1.4729346808859045,\n",
    "    random_state=42\n",
    ")\n",
    "initial_model.fit(X_train, y_train)\n",
    "\n",
    "# 2. Feature-Importance anzeigen\n",
    "importances = initial_model.feature_importances_\n",
    "print(\"Feature-Importances:\")\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    print(f\"{col}: {importances[i]}\")\n",
    "\n",
    "# 3. Feature-Selection basierend auf Importance\n",
    "selector = SelectFromModel(initial_model, threshold=\"mean\", prefit=True)  # Features oberhalb des Mittelwerts\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"Reduzierte Feature-Matrix nach Selektion: {X_train_selected.shape}\")\n",
    "\n",
    "# 4. SMOTE anwenden\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_selected, y_train)\n",
    "\n",
    "print(f\"Trainingsdaten nach SMOTE: {X_train_resampled.shape}\")\n",
    "\n",
    "# 5. Modell trainieren mit ausgewählten Features und resampleten Daten\n",
    "final_model = XGBClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.14751782232750854,\n",
    "    n_estimators=275,\n",
    "    colsample_bytree=0.7766488973382092,\n",
    "    subsample=0.9516562498035502,\n",
    "    gamma=0.03367330199720531,\n",
    "    reg_alpha=0.5167403897206998,\n",
    "    reg_lambda=1.4729346808859045,\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 6. Vorhersagen und Bewertung\n",
    "y_pred_final = final_model.predict(X_test_selected)\n",
    "print(\"Klassifikationsbericht (Finales Modell):\")\n",
    "print(classification_report(y_test, y_pred_final))\n",
    "print(f\"Genauigkeit: {accuracy_score(y_test, y_pred_final):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da0c76d-c089-4a43-8127-3b1833bcffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassifikationsbericht (PCA):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1002\n",
      "           1       0.59      0.59      0.59       908\n",
      "\n",
      "    accuracy                           0.61      1910\n",
      "   macro avg       0.61      0.61      0.61      1910\n",
      "weighted avg       0.61      0.61      0.61      1910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA anwenden, um die Dimensionen zu reduzieren\n",
    "pca = PCA(n_components=20)  # Anzahl der Hauptkomponenten anpassen\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Neues Modell trainieren\n",
    "model_pca = XGBClassifier(random_state=42)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "print(\"Klassifikationsbericht (PCA):\")\n",
    "print(classification_report(y_test, y_pred_pca))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
